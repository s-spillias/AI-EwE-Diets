\subsection{Validation Framework}

We executed model generation across three distinct phases. In phase one, we established baseline configurations for each study region by processing species occurrence data and research parameters. We terminated this phase prior to species grouping, creating standardized input states for subsequent validation iterations.

We executed five independent iterations per region in phase two. Each iteration began with species grouping and proceeded through the complete model construction sequence. We maintained fixed input parameters across iterations while allowing the AI's stochastic decision processes to generate natural variation in outputs.

\subsubsection{Study Regions}

\begin{figure}[htbp]
    \centering
    \includegraphics[width=0.8\textwidth]{figures/validation_regions.pdf}
    \caption{Map of the three validation regions used in this study: Northern Territory (orange), South East Inshore (blue), and South East Offshore (green).}
    \label{fig:validation_regions}
    \end{figure}

We validate our framework using three Australian marine regions that present distinct ecological characteristics and modeling challenges (Figure \ref{fig:validation_regions}). The Northern Territory region represents a tropical ecosystem characterized by complex reef systems, seasonal monsoon influences, and high biodiversity. This region tests the framework's ability to handle diverse species assemblages and complex trophic interactions in a dynamic environment.

The South East Inshore region represents a temperate coastal system with extensive ecological records. This region has comprehensive diet information in established databases, well-documented EwE models spanning multiple years, and active research programs. The rich availability of expert knowledge and historical data makes this region ideal for validating the framework's data integration capabilities.

The South East Offshore region presents a deep-water ecosystem that challenges the framework with data-limited conditions and unique ecological patterns. This region tests the framework's capacity to handle situations where direct observational data may be sparse and where species interactions may be less well understood. The contrasting characteristics of these three regions provide a robust test of the framework's adaptability across different ecological contexts.


\subsubsection{Group  Consistency Analysis}

We tracked each species' group assignments across iterations and calculated a consistency score:

\[
\text{Consistency Score} = \frac{\text{Number of occurrences in most common group}}{\text{Total number of iterations}}
\]

We classified species with consistency scores below 0.95 as unstable, indicating variable group assignments across iterations.

We assessed group stability using the Jaccard similarity coefficient to measure consistency of group membership between consecutive iterations:

\[
J(i,j) = \frac{|M_{i} \cap M_{j}|}{|M_{i} \cup M_{j}|}
\]

where $M_{i}$ and $M_{j}$ represented species members in iterations $i$ and $j$. We calculated the overall stability score by averaging Jaccard similarities across consecutive iteration pairs.

\subsubsection{Diet Matrix Analysis}
We analyzed diet matrix reliability by focusing on significant predator-prey interactions, which we defined as those comprising more than 5\% of a predator's diet. For each interaction, we calculated:

\begin{enumerate}
    \item Presence ratio across iterations:
    \[
    P_{ij} = \frac{\text{Number of iterations with interaction}}{n}
    \]
    where $n$ was the total number of iterations.

    \item Mean diet proportion:
    \[
    \mu_{ij} = \frac{1}{n}\sum_{k=1}^{n} x_{ijk}
    \]
    where $x_{ijk}$ represents diet proportion for predator $i$ consuming prey $j$ in iteration $k$.

    \item Stability score:
    \[
    S_{ij} = \frac{1}{n}\sum_{k=1}^{n} \frac{|x_{ijk} - \mu_{ij}|}{\max_{k}(x_{ijk})}
    \]
    where $x_{ijk}$ represents the diet proportion for predator $i$ consuming prey $j$ in iteration $k$, $\mu_{ij}$ is the mean diet proportion across iterations, and $\max_{k}(x_{ijk})$ is the maximum value across iterations. This score ranges from 0 (perfect stability) to 1 (maximum instability), with lower values indicating more consistent diet proportions across iterations.
\end{enumerate}

We chose this stability metric over traditional variance measures for several reasons. First, by normalizing deviations by the maximum value, the metric achieves scale independence, allowing meaningful comparisons between interactions of different magnitudes. For example, the sequences [0.2, 0.2, 0.2, 0.2, 0.1] and [0.02, 0.02, 0.02, 0.02, 0.01] would yield the same stability score despite having different absolute variances. Second, the bounded range between 0 and 1 provides an intuitive scale for assessing stability, unlike the unbounded nature of variance. Third, this approach effectively handles small variations in small values, ensuring that minor fluctuations in trace diet components do not disproportionately influence the stability assessment.

We classified interactions as unstable when their stability score exceeded 0.3, indicating significant variation in diet proportions across iterations. To illustrate this metric:

\begin{itemize}
    \item A stable interaction (S = 0.08) might show values [0.02, 0.02, 0.02, 0.02, 0.01], where proportions remain very similar across iterations
    \item An unstable interaction (S = 0.39) might show values [0.027, 0.25, 0.25, 0.067, 0.25], where proportions vary substantially between iterations
\end{itemize}

This metric provides a continuous measure of stability that handles both presence/absence patterns and magnitude variations in a unified way, avoiding discontinuities at zero values.

\subsubsection{Expert Evaluation Protocol}
To evaluate the quality of diet matrices generated through artificial intelligence methods, we implemented a single-blind validation framework comparing AI-generated and expert-created Ecopath with Ecosim (EwE) diet matrices across three distinct regions. Two independent domain experts were engaged to assess both matrix types without knowledge of their origin. The evaluation protocol employed a five-point Likert scale assessment, where a score of 1 indicated strong preference for the AI-generated matrix and 5 indicated strong preference for the expert-generated matrix. 

The validation framework encompassed two primary assessment criteria. First, experts evaluated the structural validity of functional group classifications within each matrix. Second, they assessed the ecological plausibility of diet proportions assigned to each functional grouping. To capture nuanced insights beyond numerical scores, experts provided qualitative feedback on the strengths and weaknesses of each matrix. This dual quantitative-qualitative approach enabled comprehensive evaluation of both methodological approaches to diet matrix construction.

\subsection{Statistical Analysis}
We conducted statistical analyses to evaluate framework performance across regions. We assessed group consistency using chi-square tests and coefficients of variation, examining the stability of species assignments across iterations. We analyzed regional differences in group characteristics using one-way ANOVA with Cohen's f effect size calculations. We evaluated trophic level patterns using Kruskal-Wallis tests to identify significant differences in trophic structure. We quantified diet matrix reliability through pairwise Spearman correlations between iterations, focusing on significant interactions (>0.05 proportion).
